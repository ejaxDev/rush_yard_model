{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec03396",
   "metadata": {},
   "source": [
    "# Base Stat Feature Engineering\n",
    "\n",
    "Builds the core per-player rolling feature set from raw game-by-game rushing stats.  \n",
    "Output: `base_stats_feature_engineering.csv` — consumed by the `train_test/` notebooks.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "| Stage | Description |\n",
    "|-------|-------------|\n",
    "| **Data Ingestion** | Load per-game RB stats from S3 (seasons 2018–2025) |\n",
    "| **Offensive Rolling Lookup** | Pre-compute leak-free rolling features per player |\n",
    "| **Data Cleaning** | Parse dates, filter to RBs only |\n",
    "| **Teammate Lookups** | Index starter / rusher presence by `(player, week, season)` |\n",
    "| **Training Assembly** | Row-by-row join of player features + competition + injury-impact metrics |\n",
    "| **Export** | Write final DataFrame to CSV |\n",
    "\n",
    "## Feature Summary\n",
    "\n",
    "| Feature Group | Windows | Description |\n",
    "|---------------|---------|-------------|\n",
    "| `rush_yards_{w}ma` | 1, 3, 5, 10 | Rolling mean rushing yards |\n",
    "| `rush_attempts_{w}ma` | 1, 3, 5, 10 | Rolling mean carries |\n",
    "| `ypc_{w}ma` | 1, 3, 5, 10 | Rolling mean yards per carry |\n",
    "| `success_rate_{w}ma` | 1, 3, 5, 10 | Rolling mean success rate |\n",
    "| `*_delta_3_5` / `*_delta_5_10` | — | Momentum: short-window minus long-window |\n",
    "| `rush_yards_vol_5`, `ypc_vol_5` | 5 | Rolling std — game-to-game consistency |\n",
    "| `min/max_rush_yards_{3,5}ma` | 3, 5 | Rolling floor / ceiling for yards |\n",
    "| `pct_of_carries_{w}ma` | 1, 3, 5 | Player's share of combined team carries |\n",
    "| `others_rush_attempts_{w}ma` | 1, 3, 5 | Sum of active teammates' rolling carries |\n",
    "| `others_been_injured_{w}ma` | 1, 3, 5 | Absent teammate workload (bucketed by weeks since last game) |\n",
    "| `carries_before_injury_{w}ma` | 1, 3, 5 | Player's carry share vs injured teammate before absence |\n",
    "\n",
    "> **Leak prevention:** all rolling windows apply `shift(1)` so the feature for game N reflects only games N−1, N−2, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a975fe",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Data Ingestion\n",
    "\n",
    "Resolve the repo root so the private `utils` module can be found, then load raw per-game rushing stats from S3 for seasons **2018–2025**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbeabde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /home/mrmath/sports_betting_empire/sports_betting_empire to sys.path\n"
     ]
    }
   ],
   "source": [
    "# Resolve the repo root dynamically so the shared `utils` module can be imported\n",
    "# regardless of where the notebook is run from within the project tree.\n",
    "#\n",
    "# NOTE: `utils` is a private module NOT included in this repository.\n",
    "# It contains custom web-scraping functions and an S3 client wrapper used\n",
    "# to fetch pre-scraped NFL data stored in a private S3 bucket. To run this\n",
    "# notebook you will need to supply your own data source and adapt\n",
    "# `utils.rush_yard_stats_from_s3()` accordingly.\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = Path.cwd().resolve().parents[3]\n",
    "print(f\"Adding {repo_root} to sys.path\")\n",
    "sys.path.append(str(repo_root))\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e13973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw base rushing stats from S3 for seasons 2018-2025.\n",
    "# Returns a DataFrame with per-game rushing stats for all players.\n",
    "base_stats = utils.rush_yard_stats_from_s3(\"base_stats\", 2018, 2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28709686",
   "metadata": {},
   "source": [
    "## 2. Offensive Rolling Feature Lookup\n",
    "\n",
    "Pre-compute all rolling features per player and store them in `offense_rush_stats_LOOKUP` — a dict keyed by player name where each value is a DataFrame indexed by game date.\n",
    "\n",
    "Building the lookup once here (rather than recalculating inside `generate_train_df`) keeps assembly fast: each feature row is a single `iloc[-1]` slice.  \n",
    "All windows use `shift(1)` so no same-game data bleeds into the feature row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ae381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a per-player lookup dictionary of rolling engineered features.\n",
    "#\n",
    "# For each player we compute, using a 1-game look-back (shift(1)) to prevent\n",
    "# data leakage:\n",
    "#   - Rolling means over 1, 3, 5, and 10 game windows for:\n",
    "#       * Rush yards        (rush_yards_Xma)\n",
    "#       * Rush attempts     (rush_attempts_Xma)\n",
    "#       * Yards per carry   (ypc_Xma)\n",
    "#       * Success rate      (success_rate_Xma)\n",
    "#   - Short-vs-long window deltas to capture momentum / trend:\n",
    "#       * rush_yards_delta_3_5, rush_yards_delta_5_10\n",
    "#       * rush_attempts_delta_3_5, rush_attempts_delta_5_10\n",
    "#       * ypc_delta_3_5, ypc_delta_5_10\n",
    "#       * success_rate_delta_3_5\n",
    "#   - Volatility (rolling std over 5 games) for yards and YPC\n",
    "#   - Rolling min/max over 3 and 5 games for yards\n",
    "#\n",
    "# Result: offense_rush_stats_LOOKUP[player_name] -> DataFrame indexed by Date\n",
    "\n",
    "offense_rush_stats_LOOKUP = {}\n",
    "for k, v in base_stats.sort_values(['Date']).groupby(['Team']):\n",
    "    for i in v['Player'].unique():\n",
    "        player_data = base_stats[base_stats['Player'] == i].sort_values(['Date'])\n",
    "\n",
    "        # --- Rolling means (shift(1) ensures no same-game leakage) ---\n",
    "        rush_yards_1ma = player_data['Yds'].shift(1).rolling(1, min_periods=1).mean()\n",
    "        rush_yards_3ma = player_data['Yds'].shift(1).rolling(3, min_periods=1).mean()\n",
    "        rush_yards_5ma = player_data['Yds'].shift(1).rolling(5, min_periods=1).mean()\n",
    "        rush_yards_10ma = player_data['Yds'].shift(1).rolling(10, min_periods=1).mean()\n",
    "\n",
    "        rush_attempts_1ma = player_data['Att'].shift(1).rolling(1, min_periods=1).mean()\n",
    "        rush_attempts_3ma = player_data['Att'].shift(1).rolling(3, min_periods=1).mean()\n",
    "        rush_attempts_5ma = player_data['Att'].shift(1).rolling(5, min_periods=1).mean()\n",
    "        rush_attempts_10ma = player_data['Att'].shift(1).rolling(10, min_periods=1).mean()\n",
    "\n",
    "        ypc_1ma = (player_data['Yds'] / player_data['Att']).shift(1).rolling(1, min_periods=1).mean()\n",
    "        ypc_3ma = (player_data['Yds'] / player_data['Att']).shift(1).rolling(3, min_periods=1).mean()\n",
    "        ypc_5ma = (player_data['Yds'] / player_data['Att']).shift(1).rolling(5, min_periods=1).mean()\n",
    "        ypc_10ma = (player_data['Yds'] / player_data['Att']).shift(1).rolling(10, min_periods=1).mean()\n",
    "\n",
    "        success_rate_1ma = player_data['Succ%'].shift(1).rolling(1, min_periods=1).mean()\n",
    "        success_rate_3ma = player_data['Succ%'].shift(1).rolling(3, min_periods=1).mean()\n",
    "        success_rate_5ma = player_data['Succ%'].shift(1).rolling(5, min_periods=1).mean()\n",
    "        success_rate_10ma = player_data['Succ%'].shift(1).rolling(10, min_periods=1).mean()\n",
    "\n",
    "        # --- Rolling min/max for range context ---\n",
    "        max_rush_yards_3ma = player_data['Yds'].shift(1).rolling(3, min_periods=1).max()\n",
    "        max_rush_yards_5ma = player_data['Yds'].shift(1).rolling(5, min_periods=1).max()\n",
    "        min_rush_yards_3ma = player_data['Yds'].shift(1).rolling(3, min_periods=1).min()\n",
    "        min_rush_yards_5ma = player_data['Yds'].shift(1).rolling(5, min_periods=1).min()\n",
    "\n",
    "        # --- Momentum / trend deltas (short window minus long window) ---\n",
    "        rush_yards_delta_3_5 = rush_yards_3ma - rush_yards_5ma\n",
    "        rush_yards_delta_5_10 = rush_yards_5ma - rush_yards_10ma\n",
    "\n",
    "        rush_attempts_delta_3_5 = rush_attempts_3ma - rush_attempts_5ma\n",
    "        rush_attempts_delta_5_10 = rush_attempts_5ma - rush_attempts_10ma\n",
    "\n",
    "        ypc_delta_3_5 = ypc_3ma - ypc_5ma\n",
    "        ypc_delta_5_10 = ypc_5ma - ypc_10ma\n",
    "\n",
    "        success_rate_delta_3_5 = success_rate_3ma - success_rate_5ma\n",
    "\n",
    "        # --- Volatility features: rolling std captures game-to-game consistency ---\n",
    "        rush_yards_vol_5 = player_data['Yds'].shift(1).rolling(5, min_periods=2).std()\n",
    "        ypc_vol_5 = (player_data['Yds'] / player_data['Att']).shift(1).rolling(5, min_periods=2).std()\n",
    "\n",
    "        base_player_stats_ma = {\n",
    "            'Date': pd.to_datetime(player_data['Date']),\n",
    "            'rush_yards_1ma': rush_yards_1ma,\n",
    "            'rush_yards_3ma': rush_yards_3ma,\n",
    "            'rush_yards_5ma': rush_yards_5ma,\n",
    "            'rush_yards_10ma': rush_yards_10ma,\n",
    "            'rush_yards_delta_3_5': rush_yards_delta_3_5,\n",
    "            'rush_yards_delta_5_10': rush_yards_delta_5_10,\n",
    "\n",
    "            'rush_attempts_1ma': rush_attempts_1ma,\n",
    "            'rush_attempts_3ma': rush_attempts_3ma,\n",
    "            'rush_attempts_5ma': rush_attempts_5ma,\n",
    "            'rush_attempts_10ma': rush_attempts_10ma,\n",
    "            'rush_attempts_delta_3_5': rush_attempts_delta_3_5,\n",
    "            'rush_attempts_delta_5_10': rush_attempts_delta_5_10,\n",
    "\n",
    "            'ypc_1ma': ypc_1ma,\n",
    "            'ypc_3ma': ypc_3ma,\n",
    "            'ypc_5ma': ypc_5ma,\n",
    "            'ypc_10ma': ypc_10ma,\n",
    "            'ypc_delta_3_5': ypc_delta_3_5,\n",
    "            'ypc_delta_5_10': ypc_delta_5_10,\n",
    "\n",
    "            'success_rate_1ma': success_rate_1ma,\n",
    "            'success_rate_3ma': success_rate_3ma,\n",
    "            'success_rate_5ma': success_rate_5ma,\n",
    "            'success_rate_10ma': success_rate_10ma,\n",
    "            'success_rate_delta_3_5': success_rate_delta_3_5,\n",
    "\n",
    "            'rush_yards_vol_5': rush_yards_vol_5,\n",
    "            'ypc_vol_5': ypc_vol_5,\n",
    "\n",
    "            'min_rush_yards_3ma': min_rush_yards_3ma,\n",
    "            'min_rush_yards_5ma': min_rush_yards_5ma,\n",
    "            'max_rush_yards_3ma': max_rush_yards_3ma,\n",
    "            'max_rush_yards_5ma': max_rush_yards_5ma,\n",
    "            'Pos.': player_data['Pos.'].iloc[0],\n",
    "        }\n",
    "\n",
    "        offense_rush_stats_LOOKUP[i] = pd.DataFrame(base_player_stats_ma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16975e",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Filtering\n",
    "\n",
    "Parse the `Date` column to `datetime` and restrict the dataset to **running backs only** (`Pos. == 'RB'`).  \n",
    "QBs and other positions that occasionally rush are excluded — the model targets RB workload specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Date column is parsed as datetime for consistent sorting and filtering\n",
    "base_stats['Date'] = pd.to_datetime(base_stats['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the dataset to running backs only.\n",
    "# QBs and other positions that occasionally rush are excluded to keep\n",
    "# the model focused on RB workload prediction.\n",
    "base_stats = base_stats[base_stats['Pos.'] == 'RB']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa438fd",
   "metadata": {},
   "source": [
    "## 4. Competition & Injury Lookup Tables\n",
    "\n",
    "Build two O(1) dicts indexed by `(player, week, season)`:\n",
    "\n",
    "| Dict | Contents |\n",
    "|------|----------|\n",
    "| `starter_lookup_by_week_season` | `True` for players marked as starters |\n",
    "| `rusher_lookup_by_week_season` | `1` for every player who recorded a carry |\n",
    "\n",
    "These are queried inside `generate_train_df` to efficiently determine whether a previously seen teammate is **active** in the current week or likely **injured** — without re-scanning the full DataFrame on every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build two O(1) lookup dictionaries keyed by (player, week, season):\n",
    "#   starter_lookup_by_week_season  - maps key -> True if the player was a starter\n",
    "#   rusher_lookup_by_week_season   - maps key -> 1 for every player who carried the ball\n",
    "#\n",
    "# These are used later in generate_train_df() to quickly determine whether a\n",
    "# previously seen teammate is currently active (healthy) or likely injured.\n",
    "starter_lookup_by_week_season = {}\n",
    "rusher_lookup_by_week_season = {}\n",
    "base_stats = base_stats.sort_values(['Date'])\n",
    "for i in range(len(base_stats)):\n",
    "    rusher = base_stats.iloc[i]\n",
    "    key = (base_stats.iloc[i]['Player'], base_stats.iloc[i]['Week'], base_stats.iloc[i]['season'])\n",
    "    if rusher['is_starter']:\n",
    "        starter_lookup_by_week_season[key] = rusher['is_starter']\n",
    "    rusher_lookup_by_week_season[key] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcb0fb",
   "metadata": {},
   "source": [
    "## 5. Training Data Assembly — `generate_train_df()`\n",
    "\n",
    "Iterates over every RB game row and assembles a feature-rich training record by combining four signal sources:\n",
    "\n",
    "1. **Player rolling features** — look up the player's pre-game rolling stats from `offense_rush_stats_LOOKUP`\n",
    "2. **Active teammate competition** — sum rolling carries of all other RBs who played the same game\n",
    "3. **Injury-impact features** — identify teammates absent from the current week; bucket their recent workload by how many weeks they've been missing (1 week → `_1ma` bucket, 2–3 weeks → `_3ma`, 4–5 weeks → `_5ma`)\n",
    "4. **Carry-share percentages** — player carries as a fraction of combined team carries across 1/3/5 windows\n",
    "\n",
    "> All lookups reference only data prior to the current game date, maintaining strict temporal separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the final training DataFrame row-by-row.\n",
    "#\n",
    "# Each row represents a single player-game observation and includes:\n",
    "#   1. Player's own rolling features (from offense_rush_stats_LOOKUP)\n",
    "#   2. Active-teammate competition metrics (same-game carry share)\n",
    "#   3. Injury-impact features (carry replacement load from recently absent teammates)\n",
    "#   4. Derived carry-share percentages across 1/3/5 game windows\n",
    "#\n",
    "# All features are computed strictly from data prior to the current game\n",
    "# to guarantee no data leakage into the training set.\n",
    "\n",
    "def generate_train_df(rush_df):\n",
    "    \"\"\"\n",
    "    Build training dataset for RB workload prediction.\n",
    "\n",
    "    Key modeling ideas:\n",
    "    - Capture teammate competition within same game\n",
    "    - Model recency-weighted injury impact of other RBs\n",
    "    - Estimate how carry share changes when injured RBs return\n",
    "    - Use rolling moving averages (1/3/5 windows) to capture workload trends\n",
    "    \"\"\"\n",
    "\n",
    "    rush_df = rush_df.sort_values(\"Date\").copy()\n",
    "    rush_df[\"game_date\"] = rush_df[\"Date\"].dt.date\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for row in rush_df.itertuples(index=False):\n",
    "\n",
    "        player_key = row.Player\n",
    "        team = row.Team\n",
    "        game_date = row.game_date\n",
    "        week = row.Week\n",
    "        season = row.season\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # PLAYER ROLLING FEATURES\n",
    "        # Look up pre-computed rolling stats for this player up to (and\n",
    "        # including) the current game date, then take the most recent row.\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        if player_key not in offense_rush_stats_LOOKUP:\n",
    "            continue\n",
    "\n",
    "        player_full_history = offense_rush_stats_LOOKUP[player_key]\n",
    "        ps = player_full_history[player_full_history[\"Date\"].dt.date <= game_date]\n",
    "\n",
    "        if ps.empty:\n",
    "            continue\n",
    "\n",
    "        player_stats_on_date = ps.iloc[-1]\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # SAME-GAME TEAMMATES\n",
    "        # Identify all other RBs who carried the ball in this game —\n",
    "        # these directly compete for carries with the target player.\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        same_game_teammates = rush_df[\n",
    "            (rush_df[\"Team\"] == team) &\n",
    "            (rush_df[\"game_date\"] == game_date) &\n",
    "            (rush_df[\"Player\"] != player_key)\n",
    "        ]\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # PREVIOUS TEAMMATES THIS SEASON\n",
    "        # Used to detect recently injured players: any RB who appeared\n",
    "        # earlier in the season but is absent from this game's active roster.\n",
    "        # de-duplicate to keep only each teammate's most recent appearance.\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        prev_teammates = rush_df[\n",
    "            (rush_df[\"Team\"] == team) &\n",
    "            (rush_df[\"game_date\"] < game_date) &\n",
    "            (rush_df[\"season\"] == season) &\n",
    "            (rush_df[\"Player\"] != player_key)\n",
    "        ].drop_duplicates([\"Player\", \"season\"], keep=\"last\")\n",
    "\n",
    "        # Accumulators for injury-impact features\n",
    "        others_been_injured_1ma = 0\n",
    "        others_been_injured_3ma = 0\n",
    "        others_been_injured_5ma = 0\n",
    "\n",
    "        # Accumulators for carry-share-before-injury features\n",
    "        carries_before_injury_1ma = 0\n",
    "        carries_before_injury_3ma = 0\n",
    "        carries_before_injury_5ma = 0\n",
    "\n",
    "        for teammate in prev_teammates.itertuples(index=False):\n",
    "\n",
    "            key = teammate.Player\n",
    "            last_active_week = teammate.Week\n",
    "\n",
    "            # Skip teammate if they are active in the current game week\n",
    "            if (key, week, season) in rusher_lookup_by_week_season:\n",
    "                continue\n",
    "\n",
    "            # Only consider teammates who went missing within the last 5 weeks\n",
    "            # (beyond that, the injury is unlikely to still affect carry share).\n",
    "            week_diff = week - last_active_week\n",
    "\n",
    "            if week_diff > 5:\n",
    "                continue\n",
    "\n",
    "            stats_df = offense_rush_stats_LOOKUP.get(key)\n",
    "            if stats_df is None:\n",
    "                continue\n",
    "\n",
    "            stats_df = stats_df[stats_df[\"Date\"].dt.date < game_date]\n",
    "            if stats_df.empty:\n",
    "                continue\n",
    "\n",
    "            last_val = stats_df.iloc[-1][\"rush_attempts_5ma\"]\n",
    "            if pd.isna(last_val):\n",
    "                continue\n",
    "\n",
    "            # Bucket the absent teammate's average workload by how recently\n",
    "            # they disappeared — closer absence = stronger carry-share impact.\n",
    "            if week_diff < 2:\n",
    "                others_been_injured_1ma += last_val\n",
    "            elif 2 <= week_diff <= 3:\n",
    "                others_been_injured_3ma += last_val\n",
    "            elif 4 <= week_diff <= 5:\n",
    "                others_been_injured_5ma += last_val\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # CARRY SHARE BEFORE INJURY\n",
    "            # Compare the target player's rolling carries vs the now-absent\n",
    "            # teammate's rolling carries at the last game the teammate played.\n",
    "            # A high share indicates the target player was dominant even before\n",
    "            # the teammate went down, reducing expected carry-share \"bonus.\"\n",
    "            # -------------------------------------------------\n",
    "\n",
    "            if len(stats_df) < 2:\n",
    "                continue  # Need at least two rows to access the pre-injury row\n",
    "\n",
    "            pre_injury_row = stats_df.iloc[-2]\n",
    "            pre_injury_date = pre_injury_row[\"Date\"]\n",
    "\n",
    "            player_hist = player_full_history[\n",
    "                player_full_history[\"Date\"] == pre_injury_date\n",
    "            ]\n",
    "\n",
    "            if player_hist.empty:\n",
    "                continue\n",
    "\n",
    "            player_pre = player_hist.iloc[-1]\n",
    "\n",
    "            for window in [1, 3, 5]:\n",
    "\n",
    "                col = f\"rush_attempts_{window}ma\"\n",
    "\n",
    "                player_val = player_pre.get(col, 0)\n",
    "                teammate_val = pre_injury_row.get(col, 0)\n",
    "\n",
    "                denom = player_val + teammate_val\n",
    "                if denom <= 0:\n",
    "                    continue\n",
    "\n",
    "                # Fraction of shared carries belonging to the target player\n",
    "                share = player_val / denom\n",
    "\n",
    "                if window == 1:\n",
    "                    carries_before_injury_1ma += share\n",
    "                elif window == 3:\n",
    "                    carries_before_injury_3ma += share\n",
    "                elif window == 5:\n",
    "                    carries_before_injury_5ma += share\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # ACTIVE TEAMMATE ROLLING AVERAGES\n",
    "        # Sum up each active same-game teammate's rolling carry averages to\n",
    "        # quantify how much competition the target player faces in this game.\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        other_stats = {\n",
    "            \"others_rush_attempts_1ma\": 0,\n",
    "            \"others_rush_attempts_3ma\": 0,\n",
    "            \"others_rush_attempts_5ma\": 0,\n",
    "        }\n",
    "\n",
    "        for teammate in same_game_teammates.itertuples(index=False):\n",
    "\n",
    "            key = teammate.Player\n",
    "            stats_df = offense_rush_stats_LOOKUP.get(key)\n",
    "            if stats_df is None:\n",
    "                continue\n",
    "\n",
    "            stats_df = stats_df[stats_df[\"Date\"].dt.date <= game_date]\n",
    "            if stats_df.empty:\n",
    "                continue\n",
    "\n",
    "            latest = stats_df.iloc[-1]\n",
    "\n",
    "            for window in [1, 3, 5]:\n",
    "                col = f\"rush_attempts_{window}ma\"\n",
    "                val = latest[col]\n",
    "                if pd.notna(val):\n",
    "                    other_stats[f\"others_rush_attempts_{window}ma\"] += val\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # CARRY SHARE PERCENTAGES\n",
    "        # Express the target player's rolling carries as a fraction of the\n",
    "        # combined team rolling carries (player + active teammates).\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        pct = {}\n",
    "\n",
    "        for window in [1, 3, 5]:\n",
    "            player_val = player_stats_on_date[f\"rush_attempts_{window}ma\"]\n",
    "            other_val = other_stats[f\"others_rush_attempts_{window}ma\"]\n",
    "\n",
    "            denom = player_val + other_val\n",
    "            pct[f\"pct_of_carries_{window}ma\"] = (\n",
    "                player_val / denom if denom > 0 else 0\n",
    "            )\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # ASSEMBLE TRAINING ROW\n",
    "        # Flatten all feature groups into a single dict and append to rows list.\n",
    "        # -------------------------------------------------\n",
    "\n",
    "        data_row = {\n",
    "            \"Player\": player_key,\n",
    "            \"Team\": team,\n",
    "            \"Date\": game_date,\n",
    "            \"Att\": row.Att,\n",
    "            \"Rush_yards\": row.Yds,\n",
    "            \"Starter\": row.is_starter,\n",
    "            **player_stats_on_date.to_dict(),\n",
    "            **other_stats,\n",
    "            **pct,\n",
    "            \"others_been_injured_1ma\": others_been_injured_1ma,\n",
    "            \"others_been_injured_3ma\": others_been_injured_3ma,\n",
    "            \"others_been_injured_5ma\": others_been_injured_5ma,\n",
    "            \"carries_before_injury_1ma\": carries_before_injury_1ma,\n",
    "            \"carries_before_injury_3ma\": carries_before_injury_3ma,\n",
    "            \"carries_before_injury_5ma\": carries_before_injury_5ma,\n",
    "        }\n",
    "\n",
    "        rows.append(data_row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a3c07",
   "metadata": {},
   "source": [
    "## 6. Generate Dataset & Export\n",
    "\n",
    "Run `generate_train_df` over the full RB dataset, then write the result to `base_stats_feature_engineering.csv`.  \n",
    "This file is the primary input for the training notebooks in `train_test/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the full training DataFrame by iterating over all RB game rows\n",
    "# and attaching the engineered features defined above.\n",
    "train_df = generate_train_df(base_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a698bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the engineered feature set to disk.\n",
    "# This CSV is consumed by the train/test notebooks in train_test/.\n",
    "train_df.to_csv('base_stats_feature_engineering.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
